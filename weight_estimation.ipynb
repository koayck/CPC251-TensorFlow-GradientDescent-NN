{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39d43a4e",
   "metadata": {},
   "source": [
    "Note: Use this template to develop your project. Do not change the steps. For each step, you may add additional cells if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9b28a8",
   "metadata": {},
   "source": [
    "#### Group Information\n",
    "\n",
    "Group No: \n",
    "\n",
    "- Member 1:\n",
    "- Member 2:\n",
    "- Member 3:\n",
    "- Member 4:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0a3c45",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79b84136",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi=False\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # only shows error messages\n",
    "\n",
    "# import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dceb4ff",
   "metadata": {},
   "source": [
    "#### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a83d38c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.286233</td>\n",
       "      <td>15.643743</td>\n",
       "      <td>-1.879915</td>\n",
       "      <td>-11.294839</td>\n",
       "      <td>15.245472</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.853398</td>\n",
       "      <td>0.129878</td>\n",
       "      <td>17.620669</td>\n",
       "      <td>3.945204</td>\n",
       "      <td>8.157459</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.285310</td>\n",
       "      <td>3.176560</td>\n",
       "      <td>12.610554</td>\n",
       "      <td>-6.063613</td>\n",
       "      <td>1.831887</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.019516</td>\n",
       "      <td>-1.967793</td>\n",
       "      <td>9.306435</td>\n",
       "      <td>-0.938714</td>\n",
       "      <td>-1.203038</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.326527</td>\n",
       "      <td>3.453234</td>\n",
       "      <td>13.855478</td>\n",
       "      <td>-5.236421</td>\n",
       "      <td>1.547216</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-2.248262</td>\n",
       "      <td>-4.619586</td>\n",
       "      <td>3.248760</td>\n",
       "      <td>9.114543</td>\n",
       "      <td>4.370790</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>7.882330</td>\n",
       "      <td>1.942559</td>\n",
       "      <td>13.304597</td>\n",
       "      <td>-2.682707</td>\n",
       "      <td>0.623444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>14.421812</td>\n",
       "      <td>-10.688891</td>\n",
       "      <td>5.242771</td>\n",
       "      <td>-2.954794</td>\n",
       "      <td>11.689658</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>5.566459</td>\n",
       "      <td>-4.118762</td>\n",
       "      <td>3.670333</td>\n",
       "      <td>7.948329</td>\n",
       "      <td>10.940144</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.861633</td>\n",
       "      <td>-10.222440</td>\n",
       "      <td>11.606533</td>\n",
       "      <td>-0.388557</td>\n",
       "      <td>4.041448</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            f1         f2         f3         f4         f5  label\n",
       "0     1.286233  15.643743  -1.879915 -11.294839  15.245472      0\n",
       "1     2.853398   0.129878  17.620669   3.945204   8.157459      1\n",
       "2     3.285310   3.176560  12.610554  -6.063613   1.831887      0\n",
       "3     2.019516  -1.967793   9.306435  -0.938714  -1.203038      0\n",
       "4    -2.326527   3.453234  13.855478  -5.236421   1.547216      0\n",
       "..         ...        ...        ...        ...        ...    ...\n",
       "995  -2.248262  -4.619586   3.248760   9.114543   4.370790      1\n",
       "996   7.882330   1.942559  13.304597  -2.682707   0.623444      0\n",
       "997  14.421812 -10.688891   5.242771  -2.954794  11.689658      1\n",
       "998   5.566459  -4.118762   3.670333   7.948329  10.940144      1\n",
       "999   0.861633 -10.222440  11.606533  -0.388557   4.041448      1\n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('classification_dataset.csv')\n",
    "df\n",
    "# \"f1\", \"f2\", \"f3\", \"f4\" and \"f5\" determines \"label\" \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0f56c6",
   "metadata": {},
   "source": [
    "#### Define the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4024775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753a2eca",
   "metadata": {},
   "source": [
    "#### Define function to perform prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bdbf2168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    # returns S(x) = 1/(1+e^(-x))\n",
    "    return 1 / (1 + tf.exp(-x)) \n",
    "\n",
    "def relu(x):\n",
    "    # returns (x > y ? x : y)\n",
    "    return tf.maximum(0, x)\n",
    "\n",
    "def forward(x, weights, biases):\n",
    "    \"\"\"\n",
    "    Forward propagation function for a two-layer fully connected neural network\n",
    "\n",
    "    Arguments:\n",
    "        x (tf.Tensor): Input tensor\n",
    "        weights (list): List of weight tensors\n",
    "        biases (list): List of bias tensors\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: Output tensor.\n",
    "    \"\"\"\n",
    "    layer1 = relu(tf.matmul(x, weights) + biases[0])\n",
    "    output = tf.matmul(layer1, weights) + biases[1]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bc735b",
   "metadata": {},
   "source": [
    "#### Define function for model training\n",
    "Display the training and validation loss values for each epoch of the training loop. The displayed value must be in 6 decimal places.<br>\n",
    "Hint: <br>\n",
    "Use `tf.GradientTape` to compute the gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe17ccc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x, y, weights, biases, learning_rate):\n",
    "    \"\"\" \n",
    "    compute the gradient and update the weights and biases.\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = forward(x, weights, biases)\n",
    "        loss = loss_fn(y, y_pred)\n",
    "    gradients = tape.gradient(loss, weights + biases)\n",
    "    for i in range(len(weights)):\n",
    "        weights[i].assign_sub(learning_rate * gradients[i])\n",
    "        biases[i].assign_sub(learning_rate * gradients[i+len(weights)])\n",
    "    return loss\n",
    "\n",
    "def fit(x_train, y_train, x_val, y_val, weights, biases, learning_rate, epochs):\n",
    "    \"\"\" \n",
    "    This function implements the training loop.\n",
    "    \"\"\"\n",
    "    train_loss_results = []\n",
    "    val_loss_results = []\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train(x_train, y_train, weights, biases, learning_rate)\n",
    "        train_loss_results.append(train_loss)\n",
    "        val_loss = loss_fn(y_val, forward(x_val, weights, biases))\n",
    "        val_loss_results.append(val_loss)\n",
    "        print(f\"Epoch {epoch}: Training loss: {train_loss}, Validation loss: {val_loss}\")\n",
    "    return train_loss_results, val_loss_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f45213",
   "metadata": {},
   "source": [
    "#### Define the tensors to hold the weights and biases (create the model)\n",
    "Hint: <br>\n",
    "Use `tf.Variable` to create the tensors.<br>\n",
    "Put the tensors in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a2e2172b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 5  # 5 features\n",
    "hidden_size = 3  # Size of the hidden layer\n",
    "output_size = 2  # Predict 2 classes\n",
    "\n",
    "# Initialize the weights and biases\n",
    "weights = [\n",
    "    tf.Variable(tf.random.normal([input_size, hidden_size]), name='w1'),\n",
    "    tf.Variable(tf.random.normal([hidden_size, output_size]), name='w2'),\n",
    "]\n",
    "\n",
    "biases = [\n",
    "    tf.Variable(tf.zeros([hidden_size]), name='b1'),\n",
    "    tf.Variable(tf.zeros([output_size]), name='b2'),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176badb8",
   "metadata": {},
   "source": [
    "#### Split the dataset\n",
    "The ratio of training and test is 7:1:2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5fa1b9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 700\n",
      "Validation set size: 100\n",
      "Test set size: 200\n"
     ]
    }
   ],
   "source": [
    "test_ratio = 0.3\n",
    "validation_ratio = 1/3\n",
    "\n",
    "'''\n",
    "Split dataset into training and test with ratio of 7:3, then split the test set into test and validation with ratio of 1:3\n",
    "'''\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_data, test_data = train_test_split(df, test_size = test_ratio, random_state=42)\n",
    "\n",
    "# Split the training and validation data into training and validation sets\n",
    "test_data, val_data = train_test_split(test_data, test_size= validation_ratio, random_state=42)\n",
    "\n",
    "# Print the sizes of the three sets\n",
    "print(\"Training set size:\", len(train_data))\n",
    "print(\"Validation set size:\", len(val_data))\n",
    "print(\"Test set size:\", len(test_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c4d6cf",
   "metadata": {},
   "source": [
    "#### Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f689b7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndf[['f1', 'f2', 'f3', 'f4', 'f5']] = sigmoid(df[['f1', 'f2', 'f3', 'f4', 'f5']]) \\nprint(df)\\n\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler to the data and transform the data\n",
    "df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# I did not use sigmoid because some values are squashed into 1 although their values were different previously \n",
    "'''\n",
    "df[['f1', 'f2', 'f3', 'f4', 'f5']] = sigmoid(df[['f1', 'f2', 'f3', 'f4', 'f5']]) \n",
    "print(df)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a2e7d6",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6304c496",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__Pack_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Shapes of all inputs must match: values[0].shape = [3,5] != values[1].shape = [3,2] [Op:Pack] name: b",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m y_train \u001b[38;5;241m=\u001b[39m train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m train_loss_results, val_loss_results \u001b[38;5;241m=\u001b[39m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbiases\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[18], line 21\u001b[0m, in \u001b[0;36mfit\u001b[1;34m(x_train, y_train, x_val, y_val, weights, biases, learning_rate, epochs)\u001b[0m\n\u001b[0;32m     19\u001b[0m val_loss_results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m---> 21\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbiases\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     train_loss_results\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[0;32m     23\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m loss_fn(y_val, forward(x_val, weights, biases))\n",
      "Cell \u001b[1;32mIn[18], line 6\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(x, y, weights, biases, learning_rate)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" \u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mcompute the gradient and update the weights and biases.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m----> 6\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbiases\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(y, y_pred)\n\u001b[0;32m      8\u001b[0m gradients \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, weights \u001b[38;5;241m+\u001b[39m biases)\n",
      "Cell \u001b[1;32mIn[17], line 21\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(x, weights, biases)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(x, weights, biases):\n\u001b[0;32m     10\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03m    Forward propagation function for a two-layer fully connected neural network\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m        tf.Tensor: Output tensor.\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m     layer1 \u001b[38;5;241m=\u001b[39m relu(\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m biases[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     22\u001b[0m     output \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mmatmul(layer1, weights) \u001b[38;5;241m+\u001b[39m biases[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\weak_tensor_ops.py:142\u001b[0m, in \u001b[0;36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    141\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    143\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    144\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:5983\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   5981\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[0;32m   5982\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m-> 5983\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__Pack_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Shapes of all inputs must match: values[0].shape = [3,5] != values[1].shape = [3,2] [Op:Pack] name: b"
     ]
    }
   ],
   "source": [
    "# Define the input features and target variable\n",
    "X_train = train_data.drop('label', axis=1)\n",
    "y_train = train_data['label']\n",
    "\n",
    "# Train the model\n",
    "train_loss_results, val_loss_results = fit(X_train, y_train, val_data.drop('label', axis=1), val_data['label'], weights, biases, learning_rate=0.01, epochs=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c41885",
   "metadata": {},
   "source": [
    "#### Display the training loss and validation loss against epoch graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f05472",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c0b4c38",
   "metadata": {},
   "source": [
    "#### Predict the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84f73b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20d715ef",
   "metadata": {},
   "source": [
    "#### Display the confusion matrix and the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35deeb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
