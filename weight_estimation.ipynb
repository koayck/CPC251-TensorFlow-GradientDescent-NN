{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39d43a4e",
   "metadata": {},
   "source": [
    "Note: Use this template to develop your project. Do not change the steps. For each step, you may add additional cells if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9b28a8",
   "metadata": {},
   "source": [
    "#### Group Information\n",
    "\n",
    "Group No: \n",
    "\n",
    "- Member 1:\n",
    "- Member 2:\n",
    "- Member 3:\n",
    "- Member 4:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0a3c45",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "79b84136",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi=False\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # only shows error messages\n",
    "\n",
    "# import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dceb4ff",
   "metadata": {},
   "source": [
    "#### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a83d38c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.286233</td>\n",
       "      <td>15.643743</td>\n",
       "      <td>-1.879915</td>\n",
       "      <td>-11.294839</td>\n",
       "      <td>15.245472</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.853398</td>\n",
       "      <td>0.129878</td>\n",
       "      <td>17.620669</td>\n",
       "      <td>3.945204</td>\n",
       "      <td>8.157459</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.285310</td>\n",
       "      <td>3.176560</td>\n",
       "      <td>12.610554</td>\n",
       "      <td>-6.063613</td>\n",
       "      <td>1.831887</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.019516</td>\n",
       "      <td>-1.967793</td>\n",
       "      <td>9.306435</td>\n",
       "      <td>-0.938714</td>\n",
       "      <td>-1.203038</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.326527</td>\n",
       "      <td>3.453234</td>\n",
       "      <td>13.855478</td>\n",
       "      <td>-5.236421</td>\n",
       "      <td>1.547216</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-2.248262</td>\n",
       "      <td>-4.619586</td>\n",
       "      <td>3.248760</td>\n",
       "      <td>9.114543</td>\n",
       "      <td>4.370790</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>7.882330</td>\n",
       "      <td>1.942559</td>\n",
       "      <td>13.304597</td>\n",
       "      <td>-2.682707</td>\n",
       "      <td>0.623444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>14.421812</td>\n",
       "      <td>-10.688891</td>\n",
       "      <td>5.242771</td>\n",
       "      <td>-2.954794</td>\n",
       "      <td>11.689658</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>5.566459</td>\n",
       "      <td>-4.118762</td>\n",
       "      <td>3.670333</td>\n",
       "      <td>7.948329</td>\n",
       "      <td>10.940144</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.861633</td>\n",
       "      <td>-10.222440</td>\n",
       "      <td>11.606533</td>\n",
       "      <td>-0.388557</td>\n",
       "      <td>4.041448</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            f1         f2         f3         f4         f5  label\n",
       "0     1.286233  15.643743  -1.879915 -11.294839  15.245472      0\n",
       "1     2.853398   0.129878  17.620669   3.945204   8.157459      1\n",
       "2     3.285310   3.176560  12.610554  -6.063613   1.831887      0\n",
       "3     2.019516  -1.967793   9.306435  -0.938714  -1.203038      0\n",
       "4    -2.326527   3.453234  13.855478  -5.236421   1.547216      0\n",
       "..         ...        ...        ...        ...        ...    ...\n",
       "995  -2.248262  -4.619586   3.248760   9.114543   4.370790      1\n",
       "996   7.882330   1.942559  13.304597  -2.682707   0.623444      0\n",
       "997  14.421812 -10.688891   5.242771  -2.954794  11.689658      1\n",
       "998   5.566459  -4.118762   3.670333   7.948329  10.940144      1\n",
       "999   0.861633 -10.222440  11.606533  -0.388557   4.041448      1\n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('classification_dataset.csv')\n",
    "df\n",
    "# \"f1\", \"f2\", \"f3\", \"f4\" and \"f5\" determines \"label\" \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0f56c6",
   "metadata": {},
   "source": [
    "#### Define the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b4024775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(y_true, y_pred):\n",
    "    # one-hot encoding\n",
    "    y_true = tf.one_hot(y_true, depth=y_pred.shape[1])\n",
    "    # convert y_true to double\n",
    "    y_true = tf.cast(y_true, tf.float64)  \n",
    "\n",
    "    #calulation using binary cross-entropy\n",
    "    loss = -(y_true * tf.math.log(y_pred) + (1 - y_true) * tf.math.log(1 - y_pred))\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753a2eca",
   "metadata": {},
   "source": [
    "#### Define function to perform prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bdbf2168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    # returns S(x) = 1/(1+e^(-x))\n",
    "    return 1 / (1 + tf.exp(-x)) \n",
    "\n",
    "def relu(x):\n",
    "    # returns (x > y ? x : y)\n",
    "    return tf.maximum(0, x)\n",
    "\n",
    "def forward(x, weights, biases):\n",
    "    \"\"\"\n",
    "    Forward propagation function for a two-layer fully connected neural network\n",
    "\n",
    "    Arguments:\n",
    "        x (tf.Tensor): Input tensor\n",
    "        weights (list): List of weight tensors\n",
    "        biases (list): List of bias tensors\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: Output tensor.\n",
    "    \"\"\"\n",
    "    layer1 = relu(tf.matmul(x,weights[0]) + biases[0])\n",
    "    logits = tf.matmul(layer1,weights[1]) + biases[1]\n",
    "    output = tf.sigmoid(logits)  # add sigmoid activation function\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bc735b",
   "metadata": {},
   "source": [
    "#### Define function for model training\n",
    "Display the training and validation loss values for each epoch of the training loop. The displayed value must be in 6 decimal places.<br>\n",
    "Hint: <br>\n",
    "Use `tf.GradientTape` to compute the gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fe17ccc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x, y, weights, biases, learning_rate):\n",
    "    \"\"\" \n",
    "    compute the gradient and update the weights and biases.\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = forward(x, weights, biases)\n",
    "        loss = loss_fn(y, y_pred)\n",
    "    gradients = tape.gradient(loss, weights + biases)\n",
    "    for i in range(len(weights)):\n",
    "        weights[i].assign_sub(learning_rate * gradients[i])\n",
    "        biases[i].assign_sub(learning_rate * gradients[i+len(weights)])\n",
    "    return loss\n",
    "\n",
    "def fit(x_train, y_train, x_val, y_val, weights, biases, learning_rate, epochs):\n",
    "    \"\"\" \n",
    "    This function implements the training loop.\n",
    "    \"\"\"\n",
    "    train_loss_results = []\n",
    "    val_loss_results = []\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train(x_train, y_train, weights, biases, learning_rate)\n",
    "        train_loss_results.append(train_loss)\n",
    "        val_loss = loss_fn(y_val, forward(x_val, weights, biases))\n",
    "        val_loss_results.append(val_loss)\n",
    "        print(f\"Epoch {epoch}: Training loss: {train_loss}, Validation loss: {val_loss}\")\n",
    "    return train_loss_results, val_loss_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f45213",
   "metadata": {},
   "source": [
    "#### Define the tensors to hold the weights and biases (create the model)\n",
    "Hint: <br>\n",
    "Use `tf.Variable` to create the tensors.<br>\n",
    "Put the tensors in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a2e2172b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 5  # 5 features\n",
    "hidden_size = 3  # Size of the hidden layer\n",
    "output_size = 2  # Predict 2 classes\n",
    "\n",
    "# Initialize the weights and biases\n",
    "weights = [\n",
    "    tf.Variable(tf.random.normal([input_size, hidden_size], dtype=tf.float64), name='input_layer_weights'),\n",
    "    tf.Variable(tf.random.normal([hidden_size, output_size], dtype=tf.float64), name='hidden_layer_weights'),\n",
    "]\n",
    "\n",
    "biases = [\n",
    "    tf.Variable(tf.zeros([hidden_size], dtype=tf.float64), name='b1'),\n",
    "    tf.Variable(tf.zeros([output_size], dtype=tf.float64), name='b2'),\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176badb8",
   "metadata": {},
   "source": [
    "#### Split the dataset\n",
    "The ratio of training and test is 7:1:2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5fa1b9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 1000\n",
      "Training set size: 700\n",
      "Validation set size: 100\n",
      "Test set size: 200\n"
     ]
    }
   ],
   "source": [
    "test_ratio = 0.3\n",
    "validation_ratio = 1/3\n",
    "\n",
    "'''\n",
    "Split dataset into training and test with ratio of 7:3, then split the test set into test and validation with ratio of 1:3\n",
    "'''\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_data, test_data = train_test_split(df, test_size = test_ratio, random_state=42)\n",
    "\n",
    "# Split the training and validation data into training and validation sets\n",
    "test_data, val_data = train_test_split(test_data, test_size= validation_ratio, random_state=42)\n",
    "\n",
    "# Print the sizes of the three sets\n",
    "print(\"Dataset size:\", len(df))\n",
    "print(\"Training set size:\", len(train_data))\n",
    "print(\"Validation set size:\", len(val_data))\n",
    "print(\"Test set size:\", len(test_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c4d6cf",
   "metadata": {},
   "source": [
    "#### Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f689b7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "#scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the data and transform the data\n",
    "#df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# Define the input features and target variable\n",
    "X_train = train_data.drop('label', axis=1)\n",
    "y_train = train_data['label']\n",
    "\n",
    "X_val = val_data.drop('label', axis=1)\n",
    "Y_val = val_data['label']\n",
    "\n",
    "\"\"\"\n",
    "X_test = test_data.drop('label', axis=1)\n",
    "Y_test = test_data['label']\n",
    "\"\"\"\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a2e7d6",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6304c496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Training loss: 0.8690236710058024, Validation loss: 0.6637179905613736\n",
      "Epoch 1: Training loss: 0.674220455262404, Validation loss: 0.6160324373607325\n",
      "Epoch 2: Training loss: 0.6124586785357938, Validation loss: 0.5949236230282899\n",
      "Epoch 3: Training loss: 0.5841672160020566, Validation loss: 0.5833425323292017\n",
      "Epoch 4: Training loss: 0.5711429931165547, Validation loss: 0.5732443274641612\n",
      "Epoch 5: Training loss: 0.5597362367379498, Validation loss: 0.5628718971102624\n",
      "Epoch 6: Training loss: 0.5483183844197153, Validation loss: 0.5522354277988216\n",
      "Epoch 7: Training loss: 0.5369167558404454, Validation loss: 0.5412846031492242\n",
      "Epoch 8: Training loss: 0.5254892834581424, Validation loss: 0.5300571172563469\n",
      "Epoch 9: Training loss: 0.5139407059818355, Validation loss: 0.5185991960000886\n",
      "Epoch 10: Training loss: 0.502287191218439, Validation loss: 0.5069658915743076\n",
      "Epoch 11: Training loss: 0.4905679023594722, Validation loss: 0.49519904337510945\n",
      "Epoch 12: Training loss: 0.47885390525813715, Validation loss: 0.48338840165501185\n",
      "Epoch 13: Training loss: 0.46719654098545105, Validation loss: 0.4715459298761428\n",
      "Epoch 14: Training loss: 0.4555826015289212, Validation loss: 0.4597807907328797\n",
      "Epoch 15: Training loss: 0.4440361847105323, Validation loss: 0.44801739683061576\n",
      "Epoch 16: Training loss: 0.4326489854985552, Validation loss: 0.4364395269482231\n",
      "Epoch 17: Training loss: 0.42151170762395873, Validation loss: 0.4250154987552768\n",
      "Epoch 18: Training loss: 0.410577323424884, Validation loss: 0.413810442116286\n",
      "Epoch 19: Training loss: 0.3998283099923601, Validation loss: 0.4027688857203897\n",
      "Epoch 20: Training loss: 0.3893274462193656, Validation loss: 0.39206979701533046\n",
      "Epoch 21: Training loss: 0.37911383655479586, Validation loss: 0.38170923007055535\n",
      "Epoch 22: Training loss: 0.3692289129452521, Validation loss: 0.3715604774430219\n",
      "Epoch 23: Training loss: 0.35962815074550286, Validation loss: 0.36179086996360654\n",
      "Epoch 24: Training loss: 0.35035080258030954, Validation loss: 0.3521655165720377\n",
      "Epoch 25: Training loss: 0.34136312715561207, Validation loss: 0.34289880585447463\n",
      "Epoch 26: Training loss: 0.33267290314698406, Validation loss: 0.3337882258579567\n",
      "Epoch 27: Training loss: 0.3243018865023839, Validation loss: 0.3253589374130469\n",
      "Epoch 28: Training loss: 0.31624206960872403, Validation loss: 0.31686122991902477\n",
      "Epoch 29: Training loss: 0.3085074225201135, Validation loss: 0.3093798260224478\n",
      "Epoch 30: Training loss: 0.3011195876154635, Validation loss: 0.3011602333833974\n",
      "Epoch 31: Training loss: 0.29401235594778563, Validation loss: 0.2945315361105665\n",
      "Epoch 32: Training loss: 0.28719139132670246, Validation loss: 0.2867213222549416\n",
      "Epoch 33: Training loss: 0.280638390337207, Validation loss: 0.2805820904847597\n",
      "Epoch 34: Training loss: 0.2743357844383861, Validation loss: 0.27333367235991524\n",
      "Epoch 35: Training loss: 0.2682928647228896, Validation loss: 0.267758018782009\n",
      "Epoch 36: Training loss: 0.2625082230041068, Validation loss: 0.2607883450840567\n",
      "Epoch 37: Training loss: 0.2569438899767067, Validation loss: 0.25603642283498457\n",
      "Epoch 38: Training loss: 0.25164119613916125, Validation loss: 0.24931884239964636\n",
      "Epoch 39: Training loss: 0.2465470154453217, Validation loss: 0.24524048961854855\n",
      "Epoch 40: Training loss: 0.24163851134908104, Validation loss: 0.23877500716141767\n",
      "Epoch 41: Training loss: 0.2369135970419539, Validation loss: 0.23486846602008288\n",
      "Epoch 42: Training loss: 0.23234145520340027, Validation loss: 0.2293434646393279\n",
      "Epoch 43: Training loss: 0.22795263949993227, Validation loss: 0.22508127452630533\n",
      "Epoch 44: Training loss: 0.2237321137858266, Validation loss: 0.22045122887826007\n",
      "Epoch 45: Training loss: 0.21967265886943244, Validation loss: 0.21621399242786418\n",
      "Epoch 46: Training loss: 0.21576208983789927, Validation loss: 0.21208932554644946\n",
      "Epoch 47: Training loss: 0.21200269266989105, Validation loss: 0.2082533390913427\n",
      "Epoch 48: Training loss: 0.2083909063318221, Validation loss: 0.20437481808600297\n",
      "Epoch 49: Training loss: 0.20491115583853478, Validation loss: 0.20085395832715514\n",
      "Epoch 50: Training loss: 0.20155799729645882, Validation loss: 0.19724381689888087\n",
      "Epoch 51: Training loss: 0.19831299257764215, Validation loss: 0.19345241504072594\n",
      "Epoch 52: Training loss: 0.19517295266548176, Validation loss: 0.19053002901506924\n",
      "Epoch 53: Training loss: 0.19215056269223466, Validation loss: 0.18711400433967604\n",
      "Epoch 54: Training loss: 0.1892432509863416, Validation loss: 0.18431967601862817\n",
      "Epoch 55: Training loss: 0.1864468205644957, Validation loss: 0.18118783144885878\n",
      "Epoch 56: Training loss: 0.18376612119764227, Validation loss: 0.1790354243957454\n",
      "Epoch 57: Training loss: 0.18120927963029346, Validation loss: 0.175603110798153\n",
      "Epoch 58: Training loss: 0.1787355654967326, Validation loss: 0.1734577233693937\n",
      "Epoch 59: Training loss: 0.17632542179373842, Validation loss: 0.1710859337196409\n",
      "Epoch 60: Training loss: 0.17402568273061414, Validation loss: 0.16815295633216262\n",
      "Epoch 61: Training loss: 0.17177573742658167, Validation loss: 0.16608515315754546\n",
      "Epoch 62: Training loss: 0.16960149091047064, Validation loss: 0.16363590285921134\n",
      "Epoch 63: Training loss: 0.16749959046656748, Validation loss: 0.16155817761469982\n",
      "Epoch 64: Training loss: 0.1654649255700169, Validation loss: 0.15930008144523364\n",
      "Epoch 65: Training loss: 0.16349425615557397, Validation loss: 0.1574053075022766\n",
      "Epoch 66: Training loss: 0.16158370192915844, Validation loss: 0.1552786067107915\n",
      "Epoch 67: Training loss: 0.15972989698608553, Validation loss: 0.1533816209022719\n",
      "Epoch 68: Training loss: 0.1579312265701575, Validation loss: 0.15152444350449318\n",
      "Epoch 69: Training loss: 0.15619302478482308, Validation loss: 0.14972319268692838\n",
      "Epoch 70: Training loss: 0.15450634703648256, Validation loss: 0.14793734457767443\n",
      "Epoch 71: Training loss: 0.15286738138265793, Validation loss: 0.14616143936371379\n",
      "Epoch 72: Training loss: 0.15128045693442696, Validation loss: 0.14481983963789766\n",
      "Epoch 73: Training loss: 0.14974631374319058, Validation loss: 0.14285766575325856\n",
      "Epoch 74: Training loss: 0.1482505584991943, Validation loss: 0.14158154136545634\n",
      "Epoch 75: Training loss: 0.14679235724529208, Validation loss: 0.13988376801169536\n",
      "Epoch 76: Training loss: 0.14538099754628372, Validation loss: 0.13867655387370667\n",
      "Epoch 77: Training loss: 0.14401798075194344, Validation loss: 0.13689676655354432\n",
      "Epoch 78: Training loss: 0.1426965207998662, Validation loss: 0.1359175884531984\n",
      "Epoch 79: Training loss: 0.14140070434576404, Validation loss: 0.1343807736753478\n",
      "Epoch 80: Training loss: 0.14014400240938532, Validation loss: 0.1331019036726391\n",
      "Epoch 81: Training loss: 0.13892331837016236, Validation loss: 0.13187610681245046\n",
      "Epoch 82: Training loss: 0.1377352247351129, Validation loss: 0.1306860025886322\n",
      "Epoch 83: Training loss: 0.13657994131204715, Validation loss: 0.12948801107916277\n",
      "Epoch 84: Training loss: 0.13545311841498686, Validation loss: 0.12832858078522863\n",
      "Epoch 85: Training loss: 0.13435565848398529, Validation loss: 0.127234819194785\n",
      "Epoch 86: Training loss: 0.13328671426224553, Validation loss: 0.12616994199783857\n",
      "Epoch 87: Training loss: 0.13224631843956314, Validation loss: 0.12509472863668672\n",
      "Epoch 88: Training loss: 0.13123104125178697, Validation loss: 0.12408631160043576\n",
      "Epoch 89: Training loss: 0.1302403859960889, Validation loss: 0.12306166311036716\n",
      "Epoch 90: Training loss: 0.1292728106050051, Validation loss: 0.12206599400968257\n",
      "Epoch 91: Training loss: 0.12832739751827757, Validation loss: 0.12110526152627489\n",
      "Epoch 92: Training loss: 0.12740345252089672, Validation loss: 0.1201769551814115\n",
      "Epoch 93: Training loss: 0.12650237541873505, Validation loss: 0.11930114142317802\n",
      "Epoch 94: Training loss: 0.12562539834722913, Validation loss: 0.11847184805754968\n",
      "Epoch 95: Training loss: 0.12477109014696829, Validation loss: 0.11760571723029432\n",
      "Epoch 96: Training loss: 0.12393621569515087, Validation loss: 0.11679020732829098\n",
      "Epoch 97: Training loss: 0.12312131429142942, Validation loss: 0.11599263508539481\n",
      "Epoch 98: Training loss: 0.12232562076526904, Validation loss: 0.1151852314462629\n",
      "Epoch 99: Training loss: 0.12154702521349303, Validation loss: 0.11439762745133432\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_loss_results, val_loss_results = fit(X_train, y_train, X_val, Y_val, weights, biases, learning_rate=1, epochs=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c41885",
   "metadata": {},
   "source": [
    "#### Display the training loss and validation loss against epoch graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f05472",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c0b4c38",
   "metadata": {},
   "source": [
    "#### Predict the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84f73b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20d715ef",
   "metadata": {},
   "source": [
    "#### Display the confusion matrix and the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35deeb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
